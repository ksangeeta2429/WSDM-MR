{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, Flatten \n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "import cPickle as pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "nlp = spacy.load('en', vectors='en_glove_cc_300_1m_vectors')\n",
    "from itertools import izip_longest\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "model_save_interval = 5\n",
    "batch_size = 256\n",
    "model_file_name = '../Models/dnn_lstm_song_user'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headers = ['song_id', 'translated_names']\n",
    "songs = pd.read_csv('../New_Data/tr_songs.csv', usecols = headers) #419615\n",
    "songs['song_name'] = songs['translated_names'].map(str).apply(lambda x : ''.join([i for i in re.findall(r'[a-zA-Z_\\s]', x)]))\n",
    "songs['song_name'] = songs['song_name'].map(str).apply(lambda x : re.sub(r'\\s+',' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Data/train.csv', usecols=['msno', 'song_id', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pd.DataFrame(train.song_id.unique(), columns=['song_id'], index=None)\n",
    "missing = y[~y.song_id.isin(songs.song_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_train = pd.DataFrame(columns = ['song_id', 'song_name'])\n",
    "missing_train['song_id'] = missing.loc[missing['song_id'].isin(train.song_id)].song_id\n",
    "missing_train['song_name'] = 'General Song'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_song_embeddings():\n",
    "    model = keras.models.load_model('../New_Data/LSTM_song_embeddings/songs_embeddings_100.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_user_model():\n",
    "    model = keras.models.load_model('../New_Data/model_user_embeddings/user_embeddings_100.h5', compile = False)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_songs_tensor(song_names, nlp, steps):\n",
    "    assert not isinstance(song_names, basestring)\n",
    "    nb_samples = len(song_names)\n",
    "    word_vec_dim = nlp(song_names[0].decode('utf8'))[0].vector.shape[0]\n",
    "    song_tensor = np.zeros((nb_samples, steps, word_vec_dim))\n",
    "    for i in xrange(len(song_names)):\n",
    "        tokens = nlp(song_names[i].decode('utf8'))\n",
    "        for j in xrange(len(tokens)):\n",
    "            if j<steps:\n",
    "                song_tensor[i,j,:] = tokens[j].vector\n",
    "    return song_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique_songs = train.song_id.unique() #No. 359966\n",
    "train_unique_songs = pd.DataFrame(train_unique_songs, columns=['song_id'], index=None)\n",
    "train_songs = songs.loc[songs['song_id'].isin(train_unique_songs['song_id'])]\n",
    "duplicated_idx = train_songs.duplicated(subset='song_id', keep='first')\n",
    "train_songs = train_songs[~duplicated_idx]\n",
    "train_songs = train_songs.append(missing_train)\n",
    "train_songs = train_songs.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del y, missing_train; \n",
    "del train_unique_songs;\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_length = 25\n",
    "train_song_mapper = dict()\n",
    "\n",
    "X = generate_songs_tensor(train_songs['song_name'], nlp, seq_length)\n",
    "train_song_mapper = dict(zip(train_songs['song_id'], X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_model = load_song_embeddings()\n",
    "#SVG(model_to_dot(song_model).create(prog='dot', format='svg'))\n",
    "user_model = load_user_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_embedding_model = Model(inputs=song_model.input,\n",
    "                                 outputs=song_model.get_layer('dense_1').output)\n",
    "user_embedding_model = Model(inputs=user_model.input,outputs=user_model.get_layer('embedding_1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno_mapper = pickle.load(open('../New_Data/model_user_embeddings/msno_mapper_py2.pkl', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_generator(data, song_mapper):\n",
    "    num_rows = len(data)\n",
    "    X_song = np.zeros((len(data), seq_length, 300), dtype='float32')\n",
    "    count = 0\n",
    "    for row_num, row in data.iterrows():\n",
    "        X_song[count,] = song_mapper[row['song_id']]\n",
    "        count += 1\n",
    "    return X_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_batch(data, msno_mapper):\n",
    "    num_rows = len(data)\n",
    "    X_msno = np.zeros((num_rows, ), dtype='str')\n",
    "    count = 0\n",
    "    for row_num, row in data.iterrows():\n",
    "        X_msno[count,] = msno_mapper[row['msno']]\n",
    "        count += 1\n",
    "    return X_msno   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_song_ids_layer = Input(shape=(100,))\n",
    "input_msno_layer = Input(shape=(50, ))\n",
    "\n",
    "combined_input = keras.layers.concatenate([input_msno_layer, input_song_ids_layer])\n",
    "\n",
    "intermediate_0 = Dense(64)(combined_input)\n",
    "output_0 = Dense(1, activation='sigmoid')(intermediate_0)\n",
    "dnn_model = keras.models.Model(inputs = [input_msno_layer, input_song_ids_layer],\n",
    "                               outputs = [output_0])\n",
    "dnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVG(model_to_dot(dnn_model).create(prog='dot', format='svg'))\n",
    "#print dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "num_complete_batches = int(math.floor(len(train)/batch_size))\n",
    "for k in range(0, num_epochs):\n",
    "    progbar = generic_utils.Progbar(len(train))\n",
    "    if k%5==0:\n",
    "        dnn_model.optimizer.lr = dnn_model.optimizer.lr * .1\n",
    "    for i in range(0, num_complete_batches):\n",
    "        subset = train[i*batch_size : (i+1)*batch_size]\n",
    "        X_song_batch = song_embedding_model.predict(embedding_generator(subset, train_song_mapper), verbose=0) \n",
    "        X_user_batch = user_embedding_model.predict(user_batch(subset, msno_mapper), verbose=0)\n",
    "        X_user_batch = X_user_batch.reshape(X_user_batch.shape[0], X_user_batch.shape[2])\n",
    "        Y_batch = subset.target \n",
    "        loss, acc = dnn_model.train_on_batch([ X_user_batch, X_song_batch], Y_batch)\n",
    "        progbar.add(X_song_batch.shape[0], values=[(\"train loss\", loss), (\"acc\", acc)])\n",
    "    if len(train) % batch_size != 0:\n",
    "        subset = train[(num_complete_batches*batch_size) : len(train)]\n",
    "        X_song_batch = song_embedding_model.predict(embedding_generator(subset, train_song_mapper), verbose=0)\n",
    "        X_user_batch = user_embedding_model.predict(user_batch(subset, msno_mapper), verbose=0)\n",
    "        X_user_batch = X_user_batch.reshape(X_user_batch.shape[0], X_user_batch.shape[2])\n",
    "        Y_batch = subset.target \n",
    "        loss, acc = dnn_model.train_on_batch([ X_user_batch, X_song_batch], Y_batch)\n",
    "        progbar.add(X_song_batch.shape[0], values=[(\"train loss\", loss), (\"acc\", acc)])\n",
    "    if k%model_save_interval == 0:\n",
    "        dnn_model.save_weights(model_file_name + '_epoch_{:03d}.hdf5'.format(k))\n",
    "\n",
    "dnn_model.save_weights(model_file_name + '_epoch_{:03d}.hdf5'.format(k))\n",
    "dnn_model.save(model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print train.index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
