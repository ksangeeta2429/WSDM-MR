{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "import gc\n",
    "import re\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, Flatten\n",
    "import cPickle as pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "nlp = spacy.load('en', vectors='en_glove_cc_300_1m_vectors')\n",
    "from itertools import izip_longest\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "seq_length = 25\n",
    "weights = '../Models/dnn_lstm_song_user_epoch_015.hdf5'\n",
    "result_path = '../Test/submission_dnn_user_song.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headers = ['song_id', 'translated_names']\n",
    "songs = pd.read_csv('../New_Data/tr_songs.csv', usecols = headers) #419615\n",
    "songs['song_name'] = songs['translated_names'].map(str).apply(lambda x : ''.join([i for i in re.findall(r'[a-zA-Z_\\s]', x)]))\n",
    "songs['song_name'] = songs['song_name'].map(str).apply(lambda x : re.sub(r'\\s+',' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../Data/test.csv', usecols=['id','msno', 'song_id'])\n",
    "y = pd.DataFrame(test.song_id.unique(), columns=['song_id'], index=None)\n",
    "missing = y[~y.song_id.isin(songs.song_id)]\n",
    "missing_test = pd.DataFrame(columns = ['song_id', 'song_name'])\n",
    "missing_test['song_id'] = missing.loc[missing['song_id'].isin(test.song_id)].song_id\n",
    "missing_test['song_name'] = 'General Song'\n",
    "test_unique_songs = test.song_id.unique() #No. 224753\n",
    "test_unique_songs = pd.DataFrame(test_unique_songs, columns=['song_id'], index=None)\n",
    "test_songs = songs.loc[songs['song_id'].isin(test_unique_songs['song_id'])]\n",
    "duplicated_idx = test_songs.duplicated(subset='song_id', keep='first')\n",
    "test_songs = test_songs[~duplicated_idx]\n",
    "test_songs = test_songs.append(missing_test)\n",
    "test_songs = test_songs.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del y, missing_test; \n",
    "del test_unique_songs;\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_song_embeddings():\n",
    "    model = keras.models.load_model('../New_Data/LSTM_song_embeddings/songs_embeddings_100.h5')\n",
    "    return model\n",
    "\n",
    "def load_user_model():\n",
    "    model = keras.models.load_model('../New_Data/model_user_embeddings/user_embeddings_100.h5', compile = False)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_songs_tensor(song_names, nlp, steps):\n",
    "    assert not isinstance(song_names, basestring)\n",
    "    nb_samples = len(song_names)\n",
    "    word_vec_dim = nlp(song_names[0].decode('utf8'))[0].vector.shape[0]\n",
    "    song_tensor = np.zeros((nb_samples, steps, word_vec_dim))\n",
    "    for i in xrange(len(song_names)):\n",
    "        tokens = nlp(song_names[i].decode('utf8'))\n",
    "        for j in xrange(len(tokens)):\n",
    "            if j<steps:\n",
    "                song_tensor[i,j,:] = tokens[j].vector\n",
    "\n",
    "    return song_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_song_mapper = dict()\n",
    "X_test = generate_songs_tensor(test_songs['song_name'], nlp, seq_length)\n",
    "test_song_mapper = dict(zip(test_songs['song_id'], X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_model = load_song_embeddings()\n",
    "#SVG(model_to_dot(song_model).create(prog='dot', format='svg'))\n",
    "user_model = load_user_model()\n",
    "\n",
    "\n",
    "song_embedding_model = Model(inputs=song_model.input,outputs=song_model.get_layer('dense_1').output)\n",
    "user_embedding_model = Model(inputs=user_model.input,outputs=user_model.get_layer('embedding_1').output)\n",
    "\n",
    "msno_mapper = pickle.load(open('../New_Data/model_user_embeddings/msno_mapper_py2.pkl', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_generator(data, song_mapper):\n",
    "    num_rows = len(data)\n",
    "    X_song = np.zeros((len(data), seq_length, 300), dtype=np.float32)\n",
    "    count = 0\n",
    "    for row_num, row in data.iterrows():\n",
    "        X_song[count,] = song_mapper[row['song_id']]\n",
    "        count += 1\n",
    "    return X_song\n",
    "\n",
    "def user_batch(data, msno_mapper):\n",
    "    num_rows = len(data)\n",
    "    X_msno = np.zeros((num_rows, ), dtype='str')\n",
    "    count = 0\n",
    "    for row_num, row in data.iterrows():\n",
    "        X_msno[count,] = msno_mapper[row['msno']]\n",
    "        count += 1\n",
    "    return X_msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_song_ids_layer = Input(shape=(100,))\n",
    "input_msno_layer = Input(shape=(50,))\n",
    "\n",
    "combined_input = keras.layers.concatenate([input_msno_layer, input_song_ids_layer])\n",
    "intermediate_0 = Dense(64)(combined_input)\n",
    "output_0 = Dense(1, activation='sigmoid')(intermediate_0)\n",
    "dnn_model = keras.models.Model(inputs = [input_msno_layer, input_song_ids_layer],\n",
    "                               outputs = [output_0])\n",
    "dnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_10 (InputLayer)            (None, 50)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_9 (InputLayer)             (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 150)           0           input_10[0][0]                   \n",
      "                                                                   input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 64)            9664        concatenate_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 1)             65          dense_9[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 9,729\n",
      "Trainable params: 9,729\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SVG(model_to_dot(dnn_model).create(prog='dot', format='svg'))\n",
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model.load_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headers = ['id', 'prob', 'target']\n",
    "new_test = pd.DataFrame(columns=headers)\n",
    "new_test['id'] = Y_list\n",
    "new_test['prob'] = predict_list\n",
    "new_test['target'] = new_test['prob'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "new_test.to_csv(result_path, index=False, header=['id', 'prob', 'target'])\n",
    "\n",
    "new_test = new_test.drop(['prob'], axis=1)\n",
    "new_test.to_csv('submitted_dnn_songs_user.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
