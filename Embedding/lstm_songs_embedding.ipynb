{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import IPython.display\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, LSTM, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "from __future__ import unicode_literals\n",
    "nlp = spacy.load('en', vectors='en_glove_cc_300_1m_vectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headers = ['song_id', 'translated_names']\n",
    "songs = pd.read_csv('../New_Data/tr_songs.csv', usecols = headers)\n",
    "duplicated_idx = songs.duplicated(subset='song_id', keep='first')\n",
    "songs = songs[~duplicated_idx]\n",
    "songs['song_name'] = songs['translated_names'].map(str).apply(lambda x : ''.join([i for i in re.findall(r'[a-zA-Z_\\s]', x)]))\n",
    "songs['song_name'] = songs['song_name'].map(str).apply(lambda x : re.sub(r'\\s+',' ',x))\n",
    "\n",
    "headers_joined = ['song_id', 'artist_name', 'composer', 'lyricist', 'genre_id']\n",
    "joined = pd.read_csv('../New_Data/joined.csv', usecols = headers_joined)\n",
    "\n",
    "data = songs.merge(joined, on='song_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.fillna(-2)\n",
    "#print data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot(column):\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoding = label_encoder.fit_transform(column)\n",
    "\n",
    "    #onehot_v = to_categorical(integer_encoding)\n",
    "    #print onehot_encoding.shape[1] #45339\n",
    "    return integer_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artist_mapper = dict()\n",
    "artists_unique = data['artist_name'].unique()\n",
    "composers_unique = data['composer'].unique()\n",
    "lyricists_unique = data['lyricist'].unique()\n",
    "genres_unique = data['genre_id'].unique()\n",
    "\n",
    "artists_oh = onehot(artists_unique)\n",
    "composers_oh = onehot(composers_unique)\n",
    "lyricists_oh = onehot(lyricists_unique)\n",
    "genres_oh = onehot(genres_unique)\n",
    "\n",
    "artists_mapper = dict(zip(artists_unique, artists_oh))\n",
    "composers_mapper = dict(zip(composers_unique, composers_oh))\n",
    "lyricists_mapper = dict(zip(lyricists_unique, lyricists_oh))\n",
    "genres_mapper = dict(zip(genres_unique, genres_oh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('artist_mapper.pkl', 'wb') as fw:\n",
    "    pickle.dump(artists_mapper, fw)\n",
    "\n",
    "with open('composer_mapper.pkl', 'wb') as fw:\n",
    "    pickle.dump(composers_mapper, fw)\n",
    "\n",
    "with open('lyricist_mapper.pkl', 'wb') as fw:\n",
    "    pickle.dump(lyricists_mapper, fw)\n",
    "\n",
    "with open('genre_mapper.pkl', 'wb') as fw:\n",
    "    pickle.dump(genres_mapper, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_length = 25\n",
    "cont = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_songs_tensor(song_names, nlp, steps):\n",
    "    assert not isinstance(song_names, basestring)\n",
    "    nb_samples = len(song_names)\n",
    "    word_vec_dim = nlp(song_names[0].decode('utf8'))[0].vector.shape[0]\n",
    "    song_tensor = np.zeros((nb_samples, steps, word_vec_dim))\n",
    "    for i in xrange(len(song_names)):\n",
    "        tokens = nlp(song_names[i].decode('utf8'))\n",
    "        for j in xrange(len(tokens)):\n",
    "            if j<steps:\n",
    "                song_tensor[i,j,:] = tokens[j].vector\n",
    "\n",
    "    return song_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_generator(data):\n",
    "    num_rows = data.shape[0]\n",
    "    #print X[10]\n",
    "    Y0 = np.empty((data.shape[0], ))\n",
    "    Y1 = np.empty((data.shape[0], ))\n",
    "    Y2 = np.empty((data.shape[0], ))\n",
    "    Y3 = np.empty((data.shape[0], ))\n",
    "\n",
    "    count = 0\n",
    "    for row_num, row in data.iterrows():\n",
    "        Y0[count] = artists_mapper[row['artist_name']]\n",
    "        Y1[count] = composers_mapper[row['composer']]\n",
    "        Y2[count] = lyricists_mapper[row['lyricist']]\n",
    "        Y3[count] = genres_mapper[row['genre_id']]\n",
    "        count += 1\n",
    "\n",
    "    return [Y0, Y1, Y2, Y3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ys = output_generator(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_songs_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cc49f0fdd140>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_songs_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'song_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_songs_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "X = generate_songs_tensor(data['song_name'], nlp, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = True\n",
    "input_dim = 300\n",
    "hidden_units_1 = 100\n",
    "hidden_units_mlp = 128\n",
    "dropout_rate = 0.4\n",
    "num_epochs = 10\n",
    "batch_size = 256\n",
    "\n",
    "input_features = Input(shape = (seq_length, input_dim))\n",
    "hidden = Dropout(dropout_rate)(LSTM(units=hidden_units_1, return_sequences=True)(input_features))\n",
    "flatten = Flatten()(hidden)\n",
    "hidden_2 = Dense(hidden_units_mlp, activation='tanh')(flatten)\n",
    "output_0 = Dense(len(artists_mapper), activation='softmax')(hidden_2)\n",
    "output_1 = Dense(len(composers_mapper), activation='softmax')(hidden_2)\n",
    "output_2 = Dense(len(lyricists_mapper), activation='softmax')(hidden_2)\n",
    "output_3 = Dense(len(genres_mapper), activation='softmax')(hidden_2)\n",
    "model = keras.models.Model(inputs = [input_features],\n",
    "                               outputs = [output_0, output_1, output_2, output_3])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if training:\n",
    "    model.fit(X, Ys, batch_size = batch_size, epochs = 5, verbose=2)\n",
    "    print(model.evaluate(X, Ys))\n",
    "    model.save('../Models/songs_embeddings_100.h5')\n",
    "else:\n",
    "    model = keras.models.load_model('../Models/songs_embeddings_100.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
