{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, Flatten \n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "import cPickle as pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "nlp = spacy.load('en', vectors='en_glove_cc_300_1m_vectors')\n",
    "from itertools import izip_longest\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "model_save_interval = 5\n",
    "batch_size = 128\n",
    "model_file_name = '../Models/dnn_lstm2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headers = ['song_id', 'translated_names']\n",
    "songs = pd.read_csv('../New_Data/tr_songs.csv', usecols = headers) #419615\n",
    "songs['song_name'] = songs['translated_names'].map(str).apply(lambda x : ''.join([i for i in re.findall(r'[a-zA-Z_\\s]', x)]))\n",
    "songs['song_name'] = songs['song_name'].map(str).apply(lambda x : re.sub(r'\\s+',' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Data/train.csv', usecols=['song_id', 'target'], index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pd.DataFrame(train.song_id.unique(), columns=['song_id'], index=None)\n",
    "missing = y[~y.song_id.isin(songs.song_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_train = pd.DataFrame(columns = ['song_id', 'song_name'])\n",
    "missing_train['song_id'] = missing.loc[missing['song_id'].isin(train.song_id)].song_id\n",
    "missing_train['song_name'] = 'General Song'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_song_embeddings():\n",
    "    model = keras.models.load_model('../New_Data/LSTM_song_embeddings/songs_embeddings_100.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_songs_tensor(song_names, nlp, steps):\n",
    "    assert not isinstance(song_names, basestring)\n",
    "    nb_samples = len(song_names)\n",
    "    word_vec_dim = nlp(song_names[0].decode('utf8'))[0].vector.shape[0]\n",
    "    song_tensor = np.zeros((nb_samples, steps, word_vec_dim))\n",
    "    for i in xrange(len(song_names)):\n",
    "        tokens = nlp(song_names[i].decode('utf8'))\n",
    "        for j in xrange(len(tokens)):\n",
    "            if j<steps:\n",
    "                song_tensor[i,j,:] = tokens[j].vector\n",
    "\n",
    "    return song_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_unique_songs = train.song_id.unique() #No. 359966\n",
    "train_unique_songs = pd.DataFrame(train_unique_songs, columns=['song_id'], index=None)\n",
    "train_songs = songs.loc[songs['song_id'].isin(train_unique_songs['song_id'])]\n",
    "duplicated_idx = train_songs.duplicated(subset='song_id', keep='first')\n",
    "train_songs = train_songs[~duplicated_idx]\n",
    "train_songs = train_songs.append(missing_train)\n",
    "train_songs = train_songs.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del y, missing_train; \n",
    "del train_unique_songs;\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_length = 25\n",
    "train_song_mapper = dict()\n",
    "\n",
    "X = generate_songs_tensor(train_songs['song_name'], nlp, seq_length)\n",
    "train_song_mapper = dict(zip(train_songs['song_id'], X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_model = load_song_embeddings()\n",
    "#SVG(model_to_dot(song_model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_embedding_model = Model(inputs=song_model.input,\n",
    "                                 outputs=song_model.get_layer('dense_1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_generator(data, song_mapper):\n",
    "    num_rows = len(data)\n",
    "    X = np.zeros((len(data), seq_length, 300), dtype='float32')\n",
    "    count = 0\n",
    "    for row_num, row in data.iterrows():\n",
    "        X[count,] = song_mapper[row['song_id']]\n",
    "        count += 1\n",
    "    return X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_song_ids_layer = Input(shape=(100,))\n",
    "intermediate_0 = Dense(64)(input_song_ids_layer)\n",
    "output_0 = Dense(1, activation='sigmoid')(intermediate_0)\n",
    "dnn_model = keras.models.Model(inputs = [input_song_ids_layer],\n",
    "                               outputs = [output_0])\n",
    "dnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVG(model_to_dot(dnn_model).create(prog='dot', format='svg'))\n",
    "#print dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "num_complete_batches = int(math.floor(len(train)/batch_size))\n",
    "for k in range(0, num_epochs):\n",
    "    progbar = generic_utils.Progbar(len(train))\n",
    "    if k%5==0:\n",
    "        dnn_model.optimizer.lr = dnn_model.optimizer.lr * .1\n",
    "    for i in range(0, num_complete_batches):\n",
    "        subset = train[i*batch_size : (i+1)*batch_size]\n",
    "        X_batch = song_embedding_model.predict(embedding_generator(subset, train_song_mapper), verbose=0)\n",
    "        Y_batch = subset.target \n",
    "        loss, acc = dnn_model.train_on_batch(X_batch, Y_batch)\n",
    "        progbar.add(X_batch.shape[0], values=[(\"train loss\", loss), (\"acc\", acc)])\n",
    "    if len(train) % batch_size != 0:\n",
    "        subset = train[(num_complete_batches*batch_size)-1 : len(train)-1]\n",
    "        X_batch = song_embedding_model.predict(embedding_generator(subset, train_song_mapper), verbose=0)\n",
    "        Y_batch = subset.target \n",
    "        loss, acc = dnn_model.train_on_batch(X_batch, Y_batch)\n",
    "        progbar.add(X_batch.shape[0], values=[(\"train loss\", loss), (\"acc\", acc)])\n",
    "    if k%model_save_interval == 0:\n",
    "        dnn_model.save_weights(model_file_name + '_epoch_{:03d}.hdf5'.format(k))\n",
    "\n",
    "dnn_model.save_weights(model_file_name + '_epoch_{:03d}.hdf5'.format(k))\n",
    "dnn_model.save('../Models/dnn_lstm_2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
