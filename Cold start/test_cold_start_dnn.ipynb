{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Activation, Embedding, Input, Concatenate, Flatten\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../New_Data/embedded_test.csv')\n",
    "train = pd.read_csv('../New_Data/embedded_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Case 1: User missing in training but song is present (in training)\n",
    "msno_song = test[~test.msno.isin(train.msno) & test.song_id.isin(train.song_id)]\n",
    "\n",
    "#Case 2: song missing in training but User exists\n",
    "song_msno = test[~test.song_id.isin(train.song_id) & test.msno.isin(train.msno)]\n",
    "\n",
    "#Case 3: both user and song is new\n",
    "both_missing = test[~test.msno.isin(train.msno) & ~test.song_id.isin(train.song_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_user_model = keras.models.load_model('../Models/dnn_no_user.h5', compile = False)\n",
    "no_user_model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "no_song_model = keras.models.load_model('../Models/dnn_no_song.h5', compile = False)\n",
    "no_song_model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "no_song_no_user_model = keras.models.load_model('../Models/dnn_no_user_no_song.h5', compile = False)\n",
    "no_song_no_user_model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32768\n",
    "lst = []\n",
    "# Case 1 testing\n",
    "predicted = no_user_model.predict([msno_song.song_id, msno_song.source_system_tab, msno_song.source_screen_name, msno_song.source_type], batch_size=batch_size, verbose=2)\n",
    "\n",
    "for x in range(len(predicted)):\n",
    "    lst.append(predicted[x][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = no_song_model.predict([song_msno.msno, song_msno.source_system_tab, song_msno.source_screen_name, song_msno.source_type], batch_size=batch_size, verbose=2)\n",
    "\n",
    "for x in range(len(predicted)):\n",
    "    lst.append(predicted[x][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = no_song_no_user_model.predict([both_missing.source_system_tab, both_missing.source_screen_name, both_missing.source_type], batch_size=batch_size, verbose=2)\n",
    "\n",
    "for x in range(len(predicted)):\n",
    "    lst.append(predicted[x][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_list = []\n",
    "Y_list.extend(both_missing.id)\n",
    "Y_list.extend(song_msno.id)\n",
    "Y_list.extend(msno_song.id)\n",
    "headers = ['id', 'target']\n",
    "new_test = pd.DataFrame(columns=headers)\n",
    "new_test['id'] = Y_list\n",
    "new_test['target'] = lst\n",
    "new_test.to_csv('../Test/cold_start_dnn.csv', index=False, header=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pravar = pd.read_csv('../Test/submission.csv')\n",
    "piyush = pd.read_csv('../Test/submission_30.csv')\n",
    "subset = pravar[pravar.id.isin(new_test.id)]\n",
    "subset = subset.merge(piyush, on='id', how='left')\n",
    "subset = subset.merge(new_test, on='id', how='left')\n",
    "subset['target'] = (subset['target_x'] + subset['target_y'] + subset.target)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96% |#####################################################################   |\r"
     ]
    }
   ],
   "source": [
    "bar = progressbar.ProgressBar()\n",
    "subset_ids = set(new_test.id.unique())\n",
    "for rownum in bar(range(len(pravar))):\n",
    "    id_ = pravar.iloc[rownum]['id']\n",
    "    if id_ in subset_ids:\n",
    "        pravar.set_value(rownum, 'target', subset[subset.id == id_].target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headers = ['id', 'target']\n",
    "pravar.to_csv('../Test/submission_cold_dnn.csv', index=False, header=headers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
