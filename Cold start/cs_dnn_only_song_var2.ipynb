{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Activation, Embedding, Input, Concatenate, Flatten\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Data/train.csv')\n",
    "test = pd.read_csv('../Data/test.csv')\n",
    "songs = pd.read_csv('../Data/songs.csv', usecols = ['song_id', 'artist_name']).astype(str)\n",
    "train = train.merge(songs, on='song_id', how='left')\n",
    "test = test.merge(songs, on='song_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:33<00:00, 21.58s/it]\n"
     ]
    }
   ],
   "source": [
    "cols = ['msno', 'song_id', 'source_screen_name', 'source_type']\n",
    "\n",
    "for col in tqdm(cols):\n",
    "    if train[col].dtype == 'object':\n",
    "        train[col] = train[col].apply(str)\n",
    "        test[col] = test[col].apply(str)\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        train_vals = list(train[col].unique())\n",
    "        test_vals = list(test[col].unique())\n",
    "        le.fit(train_vals + test_vals)\n",
    "        train[col] = le.transform(train[col])\n",
    "        test[col] = le.transform(test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Case 1: User missing in training but song is present (in training)\n",
    "msno_song = test[~test.msno.isin(train.msno) & test.song_id.isin(train.song_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_embedding_size = 64\n",
    "user_embedding_size = 64\n",
    "other_embedding_size = 16\n",
    "source_embedding_size = 10\n",
    "extra_dense = 128\n",
    "batch_size = 32768\n",
    "num_epochs = 100\n",
    "save_path = '../Models/only_song_var2.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 1: User missing in training but song is present (in training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Song Stats used in embedding\n",
    "# number of times an artist has been played \n",
    "_dict_count_artist_played_train = {k: v for k, v in train['artist_name'].value_counts().iteritems()}\n",
    "def count_artist_played(x):\n",
    "    try:\n",
    "        return _dict_count_artist_played_train[x]\n",
    "    except KeyError:\n",
    "        return 0\n",
    "        \n",
    "# number of times a song has been played\n",
    "_dict_count_song_played_train = {k: v for k, v in train['song_id'].value_counts().iteritems()}\n",
    "def count_song_played(x):\n",
    "    try:\n",
    "        return _dict_count_song_played_train[x]\n",
    "    except KeyError:\n",
    "        return 0\n",
    "\n",
    "repeated_songs_dict = train[train.target == 1].groupby(['song_id'])['target'].count().to_dict()\n",
    "def repeated_songs(x):\n",
    "    try:\n",
    "        return repeated_songs_dict[x]\n",
    "    except KeyError:\n",
    "        return 0\n",
    "\n",
    "#has anyone listened to the artist again?\n",
    "repeated_artists_dict = train[train.target == 1].groupby(['artist_name'])['target'].count().to_dict()\n",
    "def repeated_artists(x):\n",
    "    try:\n",
    "        return repeated_artists_dict[x]\n",
    "    except KeyError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['count_artist_played'] = train['artist_name'].map(str).apply(count_artist_played)\n",
    "train['count_song_played'] = train['song_id'].apply(count_song_played)\n",
    "train['repeated_song'] = train['song_id'].apply(repeated_songs)\n",
    "train['repeated_artist'] = train['artist_name'].map(str).apply(repeated_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/PAS1315/osu9187/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/users/PAS1315/osu9187/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/users/PAS1315/osu9187/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/users/PAS1315/osu9187/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "msno_song['count_artist_played'] = msno_song['artist_name'].map(str).apply(count_artist_played)\n",
    "msno_song['count_song_played'] = msno_song['song_id'].apply(count_song_played)\n",
    "msno_song['repeated_song'] = msno_song['song_id'].apply(repeated_songs)\n",
    "msno_song['repeated_artist'] = msno_song['artist_name'].map(str).apply(repeated_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sizes = {\n",
    "    'song_id': max(train.song_id.max(), test.song_id.max()) +1,\n",
    "    'source_type': max(train.source_type.max(), test.source_type.max()) +1,\n",
    "    'source_screen_name': max(train.source_screen_name.max(), test.source_screen_name.max()) +1,\n",
    "    'count_artist_played': train.count_artist_played.max() +1,\n",
    "    'count_song_played': train.count_song_played.max() +1,\n",
    "    'repeated_song': train.repeated_song.max() +1,\n",
    "    'repeated_artist': train.repeated_artist.max() +1, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_input = Input(shape = (1, ))\n",
    "#user_input = Input(shape = (1, ))\n",
    "count_artist_input = Input(shape = (1, ))\n",
    "count_song_input = Input(shape = (1, ))\n",
    "repeated_song_input = Input(shape = (1, ))\n",
    "repeated_artist_input = Input(shape = (1, ))\n",
    "s_scr_name_input = Input(shape = (1, ))\n",
    "s_type_input = Input(shape = (1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_emb = Flatten()(Embedding(output_dim = song_embedding_size, input_dim=input_sizes['song_id'], embeddings_regularizer=l2(1e-4), embeddings_initializer='glorot_uniform')(song_input))\n",
    "#user_emb = Flatten()(Embedding(output_dim = user_embedding_size, input_dim=input_sizes['msno'], embeddings_regularizer=l2(1e-4), embeddings_initializer='glorot_uniform')(user_input))\n",
    "count_artist_emb = Flatten()(Embedding(output_dim = other_embedding_size, input_dim=input_sizes['count_artist_played'], embeddings_initializer='glorot_uniform')(count_artist_input))\n",
    "count_song_emb = Flatten()(Embedding(output_dim = other_embedding_size, input_dim=input_sizes['count_song_played'], embeddings_initializer='glorot_uniform')(count_song_input))\n",
    "repeated_song_emb = Flatten()(Embedding(output_dim = other_embedding_size, input_dim=input_sizes['repeated_song'], embeddings_initializer='glorot_uniform')(repeated_song_input))\n",
    "repeated_artist_emb = Flatten()(Embedding(output_dim = other_embedding_size, input_dim=input_sizes['repeated_artist'], embeddings_initializer='glorot_uniform')(repeated_artist_input))\n",
    "s_scr_name_emb = Flatten()(Embedding(output_dim = source_embedding_size, input_dim=input_sizes['source_screen_name'], embeddings_initializer='glorot_uniform')(s_scr_name_input))\n",
    "s_type_emb = Flatten()(Embedding(output_dim = source_embedding_size, input_dim=input_sizes['source_type'], embeddings_initializer='glorot_uniform')(s_type_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Concatenate(axis=-1)([song_emb, count_artist_emb, count_song_emb, repeated_song_emb, repeated_artist_emb, s_scr_name_emb, s_type_emb])\n",
    "embedding_layer = keras.layers.Dropout(0.5)(Dense(extra_dense, activation = 'relu', kernel_initializer = 'glorot_normal')(embedding_layer))\n",
    "prediction = Dense(1, activation='sigmoid')(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_5 (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_6 (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_7 (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)          (None, 1, 64)         26869696    input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)          (None, 1, 16)         4857872     input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)         (None, 1, 16)         223584      input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)         (None, 1, 16)         174176      input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)         (None, 1, 16)         2476800     input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)         (None, 1, 10)         230         input_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)         (None, 1, 10)         130         input_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)              (None, 64)            0           embedding_8[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)              (None, 16)            0           embedding_9[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)             (None, 16)            0           embedding_10[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)             (None, 16)            0           embedding_11[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)             (None, 16)            0           embedding_12[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)             (None, 10)            0           embedding_13[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)             (None, 10)            0           embedding_14[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 148)           0           flatten_8[0][0]                  \n",
      "                                                                   flatten_9[0][0]                  \n",
      "                                                                   flatten_10[0][0]                 \n",
      "                                                                   flatten_11[0][0]                 \n",
      "                                                                   flatten_12[0][0]                 \n",
      "                                                                   flatten_13[0][0]                 \n",
      "                                                                   flatten_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 128)           19072       concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 128)           0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             129         dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 34,621,689\n",
      "Trainable params: 34,621,689\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Model(inputs=[song_input, count_artist_input, count_song_input, repeated_song_input, repeated_artist_input, s_scr_name_input, s_type_input],\n",
    "                           outputs = [prediction])\n",
    "model.summary()\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5901934 samples, validate on 1475484 samples\n",
      "Epoch 1/100\n",
      "5242880/5901934 [=========================>....] - ETA: 6s - loss: 0.6338 - acc: 0.6516"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_acc', patience = 5)\n",
    "model_checkpoint = ModelCheckpoint(save_path, save_best_only = True, save_weights_only=False)\n",
    "\n",
    "model.fit([train.song_id, train.count_artist_played, train.count_song_played, train.repeated_song, train.repeated_artist, train.source_screen_name, train.source_type],\n",
    "          [train.target], epochs = num_epochs, batch_size = batch_size, verbose=1,\n",
    "          validation_split=0.2, validation_data=None, shuffle=True,\n",
    "          callbacks = [early_stopping, model_checkpoint])\n",
    "\n",
    "model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = model.predict([msno_song.song_id, msno_song.count_artist_played, msno_song.count_song_played, msno_song.repeated_song, msno_song.repeated_artist, msno_song.source_screen_name, msno_song.source_type], batch_size=batch_size, verbose=2)\n",
    "new_test = pd.DataFrame({'id': msno_song.id, 'target': predicted.ravel()})\n",
    "new_test.to_csv('../Test/submission_only_song_var2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
