{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "songs = pd.read_csv('../Data/songs.csv').astype(str)\n",
    "members = pd.read_csv('../Data/members.csv',dtype={'city' : 'category',\n",
    "                                                      'bd' : np.uint8,\n",
    "                                                      'gender' : 'category',\n",
    "                                                      'registered_via' : 'category'},\n",
    "                             parse_dates=['registration_init_time','expiration_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Data/train.csv')\n",
    "test = pd.read_csv('../Data/test.csv')\n",
    "train = train.merge(songs, on='song_id', how='left')\n",
    "test = test.merge(songs, on='song_id', how='left')\n",
    "\n",
    "members['membership_days'] = members['expiration_date'].subtract(members['registration_init_time']).dt.days.astype(int)\n",
    "members['registration_month'] = members['registration_init_time'].dt.month\n",
    "members['expiration_year'] = members['expiration_date'].dt.year\n",
    "members = members.drop(['bd', 'gender','registration_init_time','expiration_date'], axis=1)\n",
    "\n",
    "train = train.merge(members, on='msno', how='left')\n",
    "test = test.merge(members, on='msno', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['msno', 'song_id', 'source_system_tab', 'source_screen_name', 'source_type']\n",
    "\n",
    "for col in tqdm(cols):\n",
    "    if train[col].dtype == 'object':\n",
    "        train[col] = train[col].apply(str)\n",
    "        test[col] = test[col].apply(str)\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        train_vals = list(train[col].unique())\n",
    "        test_vals = list(test[col].unique())\n",
    "        le.fit(train_vals + test_vals)\n",
    "        train[col] = le.transform(train[col])\n",
    "        test[col] = le.transform(test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of times a song has been played before\n",
    "_dict_count_song_played_train = {k: v for k, v in train['song_id'].value_counts().iteritems()}\n",
    "def count_song_played(x):\n",
    "    try:\n",
    "        return _dict_count_song_played_train[x]\n",
    "    except KeyError:\n",
    "        return 0\n",
    "    \n",
    "train['count_song_played'] = train['song_id'].map(str).apply(count_song_played).astype(np.int64)\n",
    "test['count_song_played'] = test['song_id'].map(str).apply(count_song_played).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of times an artist has been played\n",
    "_dict_count_artist_played_train = {k: v for k, v in train['artist_name'].value_counts().iteritems()}\n",
    "\n",
    "def count_artist_played(x):\n",
    "    try:\n",
    "        return _dict_count_artist_played_train[x]\n",
    "    except KeyError:\n",
    "        return 0\n",
    "\n",
    "train['count_artist_played'] = train['artist_name'].map(str).apply(count_artist_played).astype(np.int64)\n",
    "test['count_artist_played'] = test['artist_name'].map(str).apply(count_artist_played).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repeated_dict = train[train.target == 1].groupby(['msno'])['target'].count().to_dict()\n",
    "def user_repeated_songs(x):\n",
    "    try:\n",
    "        count = repeated_dict[x]\n",
    "        return count\n",
    "    except KeyError:\n",
    "        return 0\n",
    "    \n",
    "repeated_songs_dict = train[train.target == 1].groupby(['song_id'])['target'].count().to_dict()\n",
    "def repeated_songs(x):\n",
    "    try:\n",
    "        count = repeated_songs_dict[x]\n",
    "        return count\n",
    "    except KeyError:\n",
    "        return 0\n",
    "\n",
    "#has anyone listened to the artist again?\n",
    "repeated_artists_dict = train[train.target == 1].groupby(['artist_name'])['target'].count().to_dict()\n",
    "def repeated_artists(x):\n",
    "    try:\n",
    "        count = repeated_artists_dict[x]\n",
    "        return count\n",
    "    except KeyError:\n",
    "        return 0\n",
    "    \n",
    "#how frequently have people repeatedly listened to the language\n",
    "repeated_lang_dict = train[train.target == 1].groupby(['language'])['target'].count().to_dict()\n",
    "def repeated_lang(x):\n",
    "    try:\n",
    "        count = repeated_lang_dict[x]\n",
    "        return count\n",
    "    except KeyError:\n",
    "        return 0 \n",
    "    \n",
    "# number of times an artist has been played \n",
    "_dict_count_artist_played_train = {k: v for k, v in train['artist_name'].value_counts().iteritems()}\n",
    "def count_artist_played(x):\n",
    "    try:\n",
    "        return _dict_count_artist_played_train[x]\n",
    "    except KeyError:\n",
    "        return 0\n",
    "        \n",
    "# number of times a song has been played\n",
    "_dict_count_song_played_train = {k: v for k, v in train['song_id'].value_counts().iteritems()}\n",
    "def count_song_played(x):\n",
    "    try:\n",
    "        return _dict_count_song_played_train[x]\n",
    "    except KeyError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['user_repeated'] = train['msno'].map(str).apply(user_repeated_songs).astype(np.int32)\n",
    "train['repeated_song'] = train['song_id'].map(str).apply(repeated_songs).astype(np.int32)\n",
    "train['count_artist_played'] = train['artist_name'].map(str).apply(count_artist_played).astype(np.int64)\n",
    "train['count_song_played'] = train['song_id'].map(str).apply(count_song_played).astype(np.int64)\n",
    "train['repeated_artist'] = train['artist_name'].map(str).apply(repeated_artists).astype(np.int32)\n",
    "train['repeated_lang'] = train['language'].map(str).apply(repeated_lang).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['user_repeated'] = test['msno'].map(str).apply(user_repeated_songs).astype(np.int32)\n",
    "test['repeated_song'] = test['song_id'].map(str).apply(repeated_songs).astype(np.int32)\n",
    "test['count_artist_played'] = test['artist_name'].map(str).apply(count_artist_played).astype(np.int64)\n",
    "test['count_song_played'] = test['song_id'].map(str).apply(count_song_played).astype(np.int64)\n",
    "test['repeated_artist'] = test['artist_name'].map(str).apply(repeated_artists).astype(np.int32)\n",
    "test['repeated_lang'] = test['language'].map(str).apply(repeated_lang).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_system_dict = train[train.target == 1].groupby(['source_system_tab'])['target'].count().to_dict()\n",
    "def source_system_repeated(x):\n",
    "    try:\n",
    "        count = source_system_dict[x]\n",
    "        return binning(count)\n",
    "    except KeyError:\n",
    "        return 0    \n",
    "\n",
    "# number of times source_screen_name has contributed to target=1\n",
    "source_screen_dict = train[train.target == 1].groupby(['source_screen_name'])['target'].count().to_dict()\n",
    "def source_screen_repeated(x):\n",
    "    try:\n",
    "        count = source_screen_dict[x]\n",
    "        return binning(count)\n",
    "    except KeyError:\n",
    "        return 0\n",
    "\n",
    "# number of times source_type has contributed to target=1\n",
    "source_type_dict = train[train.target == 1].groupby(['source_type'])['target'].count().to_dict()\n",
    "def source_type_repeated(x):\n",
    "    try:\n",
    "        count = source_type_dict[x]\n",
    "        return binning(count)\n",
    "    except KeyError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['s_system_repeat'] = train['source_system_tab'].map(str).apply(source_system_repeated).astype(np.int32)\n",
    "train['s_screen_repeat'] = train['source_screen_name'].map(str).apply(source_screen_repeated).astype(np.int32)\n",
    "train['s_type_repeat'] = train['source_type'].map(str).apply(source_type_repeated).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['s_system_repeat'] = test['source_system_tab'].map(str).apply(source_system_repeated).astype(np.int32)\n",
    "test['s_screen_repeat'] = test['source_screen_name'].map(str).apply(source_screen_repeated).astype(np.int32)\n",
    "test['s_type_repeat'] = test['source_type'].map(str).apply(source_type_repeated).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prev = np.array(train.drop(['target'], axis=1), dtype=np.int32)\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X_prev, train.target)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X = model.transform(X_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_prev = np.array(test.drop(['id'], axis=1), dtype=np.int32)\n",
    "X_test = model.transform(X_test_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = True\n",
    "def scheduler(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "lrate = LearningRateScheduler(scheduler)\n",
    "\n",
    "model = Sequential([\n",
    "        Dense(units=1024, kernel_initializer='uniform', input_dim=X.shape[1], activation='relu'),\n",
    "        Dense(units=512, kernel_initializer='uniform', activation='relu'),\n",
    "        Dropout(0.25),\n",
    "        Dense(128, kernel_initializer='uniform', activation='relu'),\n",
    "        Dense(64, kernel_initializer='uniform', activation='relu'),\n",
    "        Dense(1, kernel_initializer='uniform', activation='sigmoid')\n",
    "    ])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "if training:\n",
    "    model.fit(X, train.target, batch_size=32768, epochs=30, validation_split=0.2, validation_data=None, shuffle=True, callbacks=[lrate])\n",
    "    model.save('../Models/dnn_lasso_var.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test, batch_size=32768, verbose=0)\n",
    "headers = ['id', 'target']\n",
    "new_test = pd.DataFrame(columns=headers)\n",
    "new_test['id'] = Y_test\n",
    "new_test['target'] = predicted\n",
    "duplicated_idx = new_test.duplicated(subset='id', keep='first')\n",
    "new_test = new_test[~duplicated_idx]\n",
    "new_test.to_csv('submission_dnn_lasso.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
