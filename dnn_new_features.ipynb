{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "songs = pd.read_csv('../Data/songs.csv').astype(str)\n",
    "members = pd.read_csv('../Data/members.csv',dtype={'city' : 'category',\n",
    "                                                      'bd' : np.uint8,\n",
    "                                                      'gender' : 'category',\n",
    "                                                      'registered_via' : 'category'},\n",
    "                             parse_dates=['registration_init_time','expiration_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Data/train.csv')\n",
    "test = pd.read_csv('../Data/test.csv')\n",
    "train = train.merge(songs, on='song_id', how='left')\n",
    "test = test.merge(songs, on='song_id', how='left')\n",
    "\n",
    "members['membership_days'] = members['expiration_date'].subtract(members['registration_init_time']).dt.days.astype(int)\n",
    "members['registration_year'] = members['registration_init_time'].dt.year\n",
    "members['expiration_year'] = members['expiration_date'].dt.year\n",
    "members = members.drop(['bd', 'gender','registration_init_time','expiration_date'], axis=1)\n",
    "\n",
    "train = train.merge(members, on='msno', how='left')\n",
    "test = test.merge(members, on='msno', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genre_id_count(x):\n",
    "    if x == 'no_genre_id':\n",
    "        return 0\n",
    "    else:\n",
    "        return x.count('|') + 1\n",
    "\n",
    "train['genre_ids'].fillna('no_genre_id',inplace=True)\n",
    "test['genre_ids'].fillna('no_genre_id',inplace=True)\n",
    "train['genre_ids_count'] = train['genre_ids'].apply(genre_id_count).astype(np.int8)\n",
    "test['genre_ids_count'] = test['genre_ids'].apply(genre_id_count).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def artist_count(x):\n",
    "    if x == 'no_artist':\n",
    "        return 0\n",
    "    else:\n",
    "        return x.count('and') + x.count(',') + x.count('feat') + x.count('&')\n",
    "\n",
    "train['artist_count'] = train['artist_name'].map(str).apply(artist_count).astype(np.int8)\n",
    "test['artist_count'] = test['artist_name'].map(str).apply(artist_count).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lyricist_count(x):\n",
    "    if x == 'no_lyricist':\n",
    "        return 0\n",
    "    else:\n",
    "        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n",
    "    return sum(map(x.count, ['|', '/', '\\\\', ';']))\n",
    "\n",
    "train['lyricist'].fillna('no_lyricist',inplace=True)\n",
    "test['lyricist'].fillna('no_lyricist',inplace=True)\n",
    "train['lyricists_count'] = train['lyricist'].map(str).apply(lyricist_count).astype(np.int8)\n",
    "test['lyricists_count'] = test['lyricist'].map(str).apply(lyricist_count).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def composer_count(x):\n",
    "    if x == 'no_composer':\n",
    "        return 0\n",
    "    else:\n",
    "        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n",
    "\n",
    "train['composer'].fillna('no_composer',inplace=True)\n",
    "test['composer'].fillna('no_composer',inplace=True)\n",
    "train['composer_count'] = train['composer'].map(str).apply(composer_count).astype(np.int8)\n",
    "test['composer_count'] = test['composer'].map(str).apply(composer_count).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of times a song has been played before\n",
    "_dict_count_song_played_train = {k: v for k, v in train['song_id'].value_counts().iteritems()}\n",
    "_dict_count_song_played_test = {k: v for k, v in test['song_id'].value_counts().iteritems()}\n",
    "def count_song_played(x):\n",
    "    try:\n",
    "        return _dict_count_song_played_train[x]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            return _dict_count_song_played_test[x]\n",
    "        except KeyError:\n",
    "            return 0\n",
    "    \n",
    "\n",
    "train['count_song_played'] = train['song_id'].map(str).apply(count_song_played).astype(np.int64)\n",
    "test['count_song_played'] = test['song_id'].map(str).apply(count_song_played).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of times an artist has been played\n",
    "_dict_count_artist_played_train = {k: v for k, v in train['artist_name'].value_counts().iteritems()}\n",
    "_dict_count_artist_played_test = {k: v for k, v in test['artist_name'].value_counts().iteritems()}\n",
    "def count_artist_played(x):\n",
    "    try:\n",
    "        return _dict_count_artist_played_train[x]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            return _dict_count_artist_played_test[x]\n",
    "        except KeyError:\n",
    "            return 0\n",
    "\n",
    "train['count_artist_played'] = train['artist_name'].map(str).apply(count_artist_played).astype(np.int64)\n",
    "test['count_artist_played'] = test['artist_name'].map(str).apply(count_artist_played).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [04:28<00:00, 12.21s/it]\n"
     ]
    }
   ],
   "source": [
    "cols = list(train.columns)\n",
    "cols.remove('target')\n",
    "\n",
    "for col in tqdm(cols):\n",
    "    if train[col].dtype == 'object':\n",
    "        train[col] = train[col].apply(str)\n",
    "        test[col] = test[col].apply(str)\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        train_vals = list(train[col].unique())\n",
    "        test_vals = list(test[col].unique())\n",
    "        le.fit(train_vals + test_vals)\n",
    "        train[col] = le.transform(train[col])\n",
    "        test[col] = le.transform(test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(train.drop(['target'], axis=1), dtype=np.int32)\n",
    "Y = train['target'].values\n",
    "\n",
    "X_test = np.array(test.drop(['id'], axis=1), dtype=np.int32)\n",
    "Y_test = test['id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_name = list(train.columns)\n",
    "X_new = X\n",
    "\n",
    "max_vals = X_new.max(axis = 0).transpose()\n",
    "min_vals = X_new.min(axis = 0).transpose()\n",
    "mean_vals = np.mean(X_new, axis = 0).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training set\n",
    "X_new = X_new - mean_vals\n",
    "X_new = X_new / (max_vals - min_vals)\n",
    "X_new = np.around(X_new,decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testing set\n",
    "X_new_test = X_test - mean_vals\n",
    "X_new_test = X_new_test / (max_vals - min_vals)\n",
    "X_new_test = np.around(X_new_test,decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X; \n",
    "del members, songs;\n",
    "del train, test;\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "18000/18000 [==============================] - 1s - loss: 0.5453 - acc: 0.7615 - val_loss: 0.5468 - val_acc: 0.7385\n",
      "Epoch 2/20\n",
      "18000/18000 [==============================] - 0s - loss: 0.4996 - acc: 0.7749 - val_loss: 0.5315 - val_acc: 0.7550\n",
      "Epoch 3/20\n",
      "18000/18000 [==============================] - 0s - loss: 0.4818 - acc: 0.7878 - val_loss: 0.5272 - val_acc: 0.7665\n",
      "Epoch 4/20\n",
      "18000/18000 [==============================] - 0s - loss: 0.4703 - acc: 0.7944 - val_loss: 0.5339 - val_acc: 0.7715\n",
      "Epoch 5/20\n",
      "18000/18000 [==============================] - 0s - loss: 0.4615 - acc: 0.8020 - val_loss: 0.6013 - val_acc: 0.7045\n",
      "Epoch 6/20\n",
      "18000/18000 [==============================] - 0s - loss: 0.4548 - acc: 0.8064 - val_loss: 0.5804 - val_acc: 0.7310\n",
      "Epoch 7/20\n",
      "18000/18000 [==============================] - 0s - loss: 0.4523 - acc: 0.8065 - val_loss: 0.6010 - val_acc: 0.7245\n",
      "Epoch 8/20\n",
      "18000/18000 [==============================] - 0s - loss: 0.4452 - acc: 0.8102 - val_loss: 0.6598 - val_acc: 0.7220\n",
      "Epoch 9/20\n",
      "18000/18000 [==============================] - 0s - loss: 0.4384 - acc: 0.8155 - val_loss: 0.7330 - val_acc: 0.6815\n",
      "Epoch 10/20\n",
      "18000/18000 [==============================] - 0s - loss: 0.4348 - acc: 0.8212 - val_loss: 0.7085 - val_acc: 0.7215\n",
      "Epoch 11/20\n",
      "18000/18000 [==============================] - 0s - loss: 0.4296 - acc: 0.8204 - val_loss: 0.8060 - val_acc: 0.6980\n",
      "Epoch 12/20\n",
      "18000/18000 [==============================] - 0s - loss: 0.4242 - acc: 0.8202 - val_loss: 0.7836 - val_acc: 0.7450\n",
      "Epoch 13/20\n",
      "18000/18000 [==============================] - 0s - loss: 0.4206 - acc: 0.8258 - val_loss: 0.7919 - val_acc: 0.7130\n",
      "Epoch 14/20\n",
      "18000/18000 [==============================] - 0s - loss: 0.4139 - acc: 0.8289 - val_loss: 0.8791 - val_acc: 0.7425\n",
      "Epoch 15/20\n",
      "18000/18000 [==============================] - 0s - loss: 0.4065 - acc: 0.8342 - val_loss: 0.8984 - val_acc: 0.7050\n",
      "Epoch 16/20\n",
      "18000/18000 [==============================] - 0s - loss: 0.4033 - acc: 0.8331 - val_loss: 0.9516 - val_acc: 0.7310\n",
      "Epoch 17/20\n",
      "18000/18000 [==============================] - 0s - loss: 0.3961 - acc: 0.8379 - val_loss: 0.9772 - val_acc: 0.7475\n",
      "Epoch 18/20\n",
      "18000/18000 [==============================] - 0s - loss: 0.3937 - acc: 0.8381 - val_loss: 1.1055 - val_acc: 0.6710\n",
      "Epoch 19/20\n",
      "18000/18000 [==============================] - 0s - loss: 0.3851 - acc: 0.8429 - val_loss: 0.9867 - val_acc: 0.7325\n",
      "Epoch 20/20\n",
      "18000/18000 [==============================] - 0s - loss: 0.3818 - acc: 0.8423 - val_loss: 0.9265 - val_acc: 0.7465\n"
     ]
    }
   ],
   "source": [
    "training = True\n",
    "model = Sequential([\n",
    "        Dense(units=1024, kernel_initializer='uniform', input_dim=X_new.shape[1], activation='relu'),\n",
    "        Dense(units=512, kernel_initializer='uniform', activation='relu'),\n",
    "        Dropout(0.25),\n",
    "        Dense(128, kernel_initializer='uniform', activation='relu'),\n",
    "        Dense(64, kernel_initializer='uniform', activation='relu'),\n",
    "        Dense(1, kernel_initializer='uniform', activation='sigmoid')\n",
    "    ])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "if training:\n",
    "    model.fit(X_new, Y, batch_size=256, epochs=20, validation_split=0.1, validation_data=None, shuffle=True)\n",
    "    model.save('../Models/dnn_new_feats.h5')\n",
    "else:\n",
    "    weights = '../Models/dnn_new_feats.h5'\n",
    "    model.load_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(X_new_test, batch_size=256, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headers = ['id', 'prob', 'target']\n",
    "new_test = pd.DataFrame(columns=headers)\n",
    "new_test['id'] = Y_test\n",
    "new_test['prob'] = predicted\n",
    "\n",
    "duplicated_idx = new_test.duplicated(subset='id', keep='first')\n",
    "new_test = new_test[~duplicated_idx]\n",
    "new_test['target'] = new_test['prob'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "new_test.to_csv('../Test/submission_dnn_new_feat.csv', index=False, header=headers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
